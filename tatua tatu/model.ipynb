{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import LSTM, Dense, Bidirectional, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number1</th>\n",
       "      <th>Number2</th>\n",
       "      <th>Number3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Number1 Number2 Number3\n",
       "0      6       9        2\n",
       "1      5       4        8\n",
       "2      1       6        9\n",
       "3      5       9        0\n",
       "4      5       0        4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Read the data from the CSV file into a DataFrame, specifying the encoding and column names\n",
    "df = pd.read_csv('data.csv', header=None, names=['Draw', 'Date', 'Numbers'], encoding='utf-8')\n",
    "\n",
    "# Split the Numbers column into separate columns\n",
    "df[['Number1', 'Number2', 'Number3']] = df['Numbers'].str.split('-', expand=True)\n",
    "\n",
    "# Drop the original Numbers column\n",
    "df.drop('Numbers', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "df.drop('Date', axis=1, inplace=True)\n",
    "df.drop('Draw', axis=1, inplace=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19980, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19980 entries, 0 to 19979\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Number1  19980 non-null  object\n",
      " 1   Number2  19980 non-null  object\n",
      " 2   Number3  19980 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 468.4+ KB\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.512064</td>\n",
       "      <td>1.556031</td>\n",
       "      <td>-0.866826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.163963</td>\n",
       "      <td>-0.180250</td>\n",
       "      <td>1.228743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.228442</td>\n",
       "      <td>0.514262</td>\n",
       "      <td>1.578005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.163963</td>\n",
       "      <td>1.556031</td>\n",
       "      <td>-1.565349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.163963</td>\n",
       "      <td>-1.569275</td>\n",
       "      <td>-0.168303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  0.512064  1.556031 -0.866826\n",
       "1  0.163963 -0.180250  1.228743\n",
       "2 -1.228442  0.514262  1.578005\n",
       "3  0.163963  1.556031 -1.565349\n",
       "4  0.163963 -1.569275 -0.168303"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(df.values)\n",
    "transformed_dataset = scaler.transform(df.values)\n",
    "transformed_df = pd.DataFrame(data=transformed_dataset, index=df.index)\n",
    "transformed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19980"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_rows = df.values.shape[0]\n",
    "number_of_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_length = 7\n",
    "window_length\n",
    "# Balls counts\n",
    "number_of_features = df.values.shape[1]\n",
    "number_of_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.empty([ number_of_rows - window_length, window_length, number_of_features], dtype=float)\n",
    "y = np.empty([ number_of_rows - window_length, number_of_features], dtype=float)\n",
    "for i in range(0, number_of_rows-window_length):\n",
    "    X[i] = transformed_df.iloc[i : i+window_length, 0 : number_of_features]\n",
    "    y[i] = transformed_df.iloc[i+window_length : i+window_length+1, 0 : number_of_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19973, 7, 3)\n",
      "(19973, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Bidirectional(LSTM(240, input_shape = (window_length, number_of_features), return_sequences = True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Bidirectional(LSTM(240, input_shape = (window_length, number_of_features), return_sequences = True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Bidirectional(LSTM(240, input_shape = (window_length, number_of_features), return_sequences = True)))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Bidirectional(LSTM(240, input_shape = (window_length, number_of_features), return_sequences = True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Bidirectional(LSTM(240, input_shape = (window_length, number_of_features), return_sequences = False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(59))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(number_of_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss ='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "200/200 - 163s - loss: 1.0004 - accuracy: 0.3387 - 163s/epoch - 815ms/step\n",
      "Epoch 2/300\n",
      "200/200 - 138s - loss: 1.0001 - accuracy: 0.3308 - 138s/epoch - 690ms/step\n",
      "Epoch 3/300\n",
      "200/200 - 144s - loss: 1.0000 - accuracy: 0.3449 - 144s/epoch - 722ms/step\n",
      "Epoch 4/300\n",
      "200/200 - 144s - loss: 1.0000 - accuracy: 0.3336 - 144s/epoch - 720ms/step\n",
      "Epoch 5/300\n",
      "200/200 - 150s - loss: 1.0000 - accuracy: 0.3346 - 150s/epoch - 751ms/step\n",
      "Epoch 6/300\n",
      "200/200 - 152s - loss: 1.0000 - accuracy: 0.3371 - 152s/epoch - 758ms/step\n",
      "Epoch 7/300\n",
      "200/200 - 153s - loss: 0.9999 - accuracy: 0.3417 - 153s/epoch - 765ms/step\n",
      "Epoch 8/300\n",
      "200/200 - 151s - loss: 1.0000 - accuracy: 0.3318 - 151s/epoch - 757ms/step\n",
      "Epoch 9/300\n",
      "200/200 - 151s - loss: 0.9998 - accuracy: 0.3417 - 151s/epoch - 754ms/step\n",
      "Epoch 10/300\n",
      "200/200 - 156s - loss: 0.9999 - accuracy: 0.3259 - 156s/epoch - 778ms/step\n",
      "Epoch 11/300\n",
      "200/200 - 158s - loss: 0.9998 - accuracy: 0.3345 - 158s/epoch - 790ms/step\n",
      "Epoch 12/300\n",
      "200/200 - 157s - loss: 0.9999 - accuracy: 0.3386 - 157s/epoch - 783ms/step\n",
      "Epoch 13/300\n",
      "200/200 - 156s - loss: 0.9999 - accuracy: 0.3369 - 156s/epoch - 781ms/step\n",
      "Epoch 14/300\n",
      "200/200 - 155s - loss: 0.9998 - accuracy: 0.3449 - 155s/epoch - 773ms/step\n",
      "Epoch 15/300\n",
      "200/200 - 152s - loss: 0.9998 - accuracy: 0.3379 - 152s/epoch - 759ms/step\n",
      "Epoch 16/300\n",
      "200/200 - 157s - loss: 0.9998 - accuracy: 0.3412 - 157s/epoch - 785ms/step\n",
      "Epoch 17/300\n",
      "200/200 - 156s - loss: 0.9998 - accuracy: 0.3369 - 156s/epoch - 780ms/step\n",
      "Epoch 18/300\n",
      "200/200 - 157s - loss: 0.9998 - accuracy: 0.3322 - 157s/epoch - 785ms/step\n",
      "Epoch 19/300\n",
      "200/200 - 156s - loss: 0.9997 - accuracy: 0.3370 - 156s/epoch - 781ms/step\n",
      "Epoch 20/300\n",
      "200/200 - 153s - loss: 0.9996 - accuracy: 0.3376 - 153s/epoch - 767ms/step\n",
      "Epoch 21/300\n",
      "200/200 - 156s - loss: 0.9998 - accuracy: 0.3369 - 156s/epoch - 779ms/step\n",
      "Epoch 22/300\n",
      "200/200 - 154s - loss: 0.9998 - accuracy: 0.3373 - 154s/epoch - 768ms/step\n",
      "Epoch 23/300\n",
      "200/200 - 158s - loss: 0.9996 - accuracy: 0.3376 - 158s/epoch - 790ms/step\n",
      "Epoch 24/300\n",
      "200/200 - 157s - loss: 0.9996 - accuracy: 0.3469 - 157s/epoch - 785ms/step\n",
      "Epoch 25/300\n",
      "200/200 - 156s - loss: 0.9996 - accuracy: 0.3440 - 156s/epoch - 782ms/step\n",
      "Epoch 26/300\n",
      "200/200 - 153s - loss: 0.9996 - accuracy: 0.3422 - 153s/epoch - 765ms/step\n",
      "Epoch 27/300\n",
      "200/200 - 158s - loss: 0.9995 - accuracy: 0.3386 - 158s/epoch - 788ms/step\n",
      "Epoch 28/300\n",
      "200/200 - 156s - loss: 0.9996 - accuracy: 0.3398 - 156s/epoch - 779ms/step\n",
      "Epoch 29/300\n",
      "200/200 - 157s - loss: 0.9995 - accuracy: 0.3447 - 157s/epoch - 783ms/step\n",
      "Epoch 30/300\n",
      "200/200 - 157s - loss: 0.9996 - accuracy: 0.3455 - 157s/epoch - 787ms/step\n",
      "Epoch 31/300\n",
      "200/200 - 154s - loss: 0.9996 - accuracy: 0.3449 - 154s/epoch - 771ms/step\n",
      "Epoch 32/300\n",
      "200/200 - 153s - loss: 0.9995 - accuracy: 0.3420 - 153s/epoch - 766ms/step\n",
      "Epoch 33/300\n",
      "200/200 - 157s - loss: 0.9995 - accuracy: 0.3457 - 157s/epoch - 783ms/step\n",
      "Epoch 34/300\n",
      "200/200 - 158s - loss: 0.9994 - accuracy: 0.3473 - 158s/epoch - 791ms/step\n",
      "Epoch 35/300\n",
      "200/200 - 158s - loss: 0.9993 - accuracy: 0.3415 - 158s/epoch - 789ms/step\n",
      "Epoch 36/300\n",
      "200/200 - 157s - loss: 0.9994 - accuracy: 0.3435 - 157s/epoch - 786ms/step\n",
      "Epoch 37/300\n",
      "200/200 - 154s - loss: 0.9993 - accuracy: 0.3399 - 154s/epoch - 772ms/step\n",
      "Epoch 38/300\n",
      "200/200 - 154s - loss: 0.9993 - accuracy: 0.3393 - 154s/epoch - 772ms/step\n",
      "Epoch 39/300\n",
      "200/200 - 157s - loss: 0.9991 - accuracy: 0.3473 - 157s/epoch - 784ms/step\n",
      "Epoch 40/300\n",
      "200/200 - 156s - loss: 0.9993 - accuracy: 0.3316 - 156s/epoch - 781ms/step\n",
      "Epoch 41/300\n",
      "200/200 - 156s - loss: 0.9992 - accuracy: 0.3474 - 156s/epoch - 782ms/step\n",
      "Epoch 42/300\n",
      "200/200 - 155s - loss: 0.9991 - accuracy: 0.3370 - 155s/epoch - 776ms/step\n",
      "Epoch 43/300\n",
      "200/200 - 153s - loss: 0.9991 - accuracy: 0.3464 - 153s/epoch - 764ms/step\n",
      "Epoch 44/300\n",
      "200/200 - 155s - loss: 0.9991 - accuracy: 0.3457 - 155s/epoch - 776ms/step\n",
      "Epoch 45/300\n",
      "200/200 - 157s - loss: 0.9990 - accuracy: 0.3400 - 157s/epoch - 787ms/step\n",
      "Epoch 46/300\n",
      "200/200 - 158s - loss: 0.9989 - accuracy: 0.3434 - 158s/epoch - 788ms/step\n",
      "Epoch 47/300\n",
      "200/200 - 157s - loss: 0.9988 - accuracy: 0.3422 - 157s/epoch - 785ms/step\n",
      "Epoch 48/300\n",
      "200/200 - 155s - loss: 0.9987 - accuracy: 0.3424 - 155s/epoch - 777ms/step\n",
      "Epoch 49/300\n",
      "200/200 - 153s - loss: 0.9986 - accuracy: 0.3407 - 153s/epoch - 763ms/step\n",
      "Epoch 50/300\n",
      "200/200 - 158s - loss: 0.9987 - accuracy: 0.3404 - 158s/epoch - 791ms/step\n",
      "Epoch 51/300\n",
      "200/200 - 157s - loss: 0.9986 - accuracy: 0.3388 - 157s/epoch - 783ms/step\n",
      "Epoch 52/300\n",
      "200/200 - 157s - loss: 0.9986 - accuracy: 0.3450 - 157s/epoch - 784ms/step\n",
      "Epoch 53/300\n",
      "200/200 - 157s - loss: 0.9985 - accuracy: 0.3490 - 157s/epoch - 783ms/step\n",
      "Epoch 54/300\n",
      "200/200 - 155s - loss: 0.9984 - accuracy: 0.3406 - 155s/epoch - 774ms/step\n",
      "Epoch 55/300\n",
      "200/200 - 155s - loss: 0.9983 - accuracy: 0.3438 - 155s/epoch - 775ms/step\n",
      "Epoch 56/300\n",
      "200/200 - 157s - loss: 0.9982 - accuracy: 0.3496 - 157s/epoch - 786ms/step\n",
      "Epoch 57/300\n",
      "200/200 - 159s - loss: 0.9981 - accuracy: 0.3492 - 159s/epoch - 795ms/step\n",
      "Epoch 58/300\n",
      "200/200 - 157s - loss: 0.9980 - accuracy: 0.3475 - 157s/epoch - 783ms/step\n",
      "Epoch 59/300\n",
      "200/200 - 157s - loss: 0.9978 - accuracy: 0.3460 - 157s/epoch - 787ms/step\n",
      "Epoch 60/300\n",
      "200/200 - 153s - loss: 0.9978 - accuracy: 0.3529 - 153s/epoch - 767ms/step\n",
      "Epoch 61/300\n",
      "200/200 - 154s - loss: 0.9976 - accuracy: 0.3485 - 154s/epoch - 769ms/step\n",
      "Epoch 62/300\n",
      "200/200 - 157s - loss: 0.9975 - accuracy: 0.3450 - 157s/epoch - 785ms/step\n",
      "Epoch 63/300\n",
      "200/200 - 157s - loss: 0.9973 - accuracy: 0.3430 - 157s/epoch - 786ms/step\n",
      "Epoch 64/300\n",
      "200/200 - 157s - loss: 0.9972 - accuracy: 0.3457 - 157s/epoch - 783ms/step\n",
      "Epoch 65/300\n",
      "200/200 - 156s - loss: 0.9969 - accuracy: 0.3493 - 156s/epoch - 778ms/step\n",
      "Epoch 66/300\n",
      "200/200 - 153s - loss: 0.9968 - accuracy: 0.3479 - 153s/epoch - 767ms/step\n",
      "Epoch 67/300\n",
      "200/200 - 155s - loss: 0.9966 - accuracy: 0.3435 - 155s/epoch - 775ms/step\n",
      "Epoch 68/300\n",
      "200/200 - 157s - loss: 0.9966 - accuracy: 0.3540 - 157s/epoch - 785ms/step\n",
      "Epoch 69/300\n",
      "200/200 - 158s - loss: 0.9962 - accuracy: 0.3486 - 158s/epoch - 789ms/step\n",
      "Epoch 70/300\n",
      "200/200 - 157s - loss: 0.9960 - accuracy: 0.3471 - 157s/epoch - 785ms/step\n",
      "Epoch 71/300\n",
      "200/200 - 153s - loss: 0.9958 - accuracy: 0.3497 - 153s/epoch - 765ms/step\n",
      "Epoch 72/300\n",
      "200/200 - 152s - loss: 0.9953 - accuracy: 0.3543 - 152s/epoch - 760ms/step\n",
      "Epoch 73/300\n",
      "200/200 - 157s - loss: 0.9951 - accuracy: 0.3559 - 157s/epoch - 786ms/step\n",
      "Epoch 74/300\n",
      "200/200 - 156s - loss: 0.9951 - accuracy: 0.3509 - 156s/epoch - 782ms/step\n",
      "Epoch 75/300\n",
      "200/200 - 158s - loss: 0.9945 - accuracy: 0.3564 - 158s/epoch - 788ms/step\n",
      "Epoch 76/300\n",
      "200/200 - 156s - loss: 0.9942 - accuracy: 0.3511 - 156s/epoch - 781ms/step\n",
      "Epoch 77/300\n",
      "200/200 - 155s - loss: 0.9938 - accuracy: 0.3519 - 155s/epoch - 774ms/step\n",
      "Epoch 78/300\n",
      "200/200 - 153s - loss: 0.9930 - accuracy: 0.3601 - 153s/epoch - 766ms/step\n",
      "Epoch 79/300\n",
      "200/200 - 157s - loss: 0.9929 - accuracy: 0.3543 - 157s/epoch - 787ms/step\n",
      "Epoch 80/300\n",
      "200/200 - 158s - loss: 0.9922 - accuracy: 0.3574 - 158s/epoch - 788ms/step\n",
      "Epoch 81/300\n",
      "200/200 - 158s - loss: 0.9915 - accuracy: 0.3583 - 158s/epoch - 789ms/step\n",
      "Epoch 82/300\n",
      "200/200 - 157s - loss: 0.9915 - accuracy: 0.3550 - 157s/epoch - 786ms/step\n",
      "Epoch 83/300\n",
      "200/200 - 152s - loss: 0.9904 - accuracy: 0.3584 - 152s/epoch - 760ms/step\n",
      "Epoch 84/300\n",
      "200/200 - 156s - loss: 0.9901 - accuracy: 0.3596 - 156s/epoch - 778ms/step\n",
      "Epoch 85/300\n",
      "200/200 - 157s - loss: 0.9890 - accuracy: 0.3605 - 157s/epoch - 783ms/step\n",
      "Epoch 86/300\n",
      "200/200 - 157s - loss: 0.9886 - accuracy: 0.3585 - 157s/epoch - 784ms/step\n",
      "Epoch 87/300\n",
      "200/200 - 157s - loss: 0.9873 - accuracy: 0.3642 - 157s/epoch - 785ms/step\n",
      "Epoch 88/300\n",
      "200/200 - 155s - loss: 0.9864 - accuracy: 0.3631 - 155s/epoch - 773ms/step\n",
      "Epoch 89/300\n",
      "200/200 - 152s - loss: 0.9858 - accuracy: 0.3643 - 152s/epoch - 762ms/step\n",
      "Epoch 90/300\n",
      "200/200 - 156s - loss: 0.9841 - accuracy: 0.3687 - 156s/epoch - 782ms/step\n",
      "Epoch 91/300\n",
      "200/200 - 157s - loss: 0.9834 - accuracy: 0.3679 - 157s/epoch - 785ms/step\n",
      "Epoch 92/300\n",
      "200/200 - 156s - loss: 0.9812 - accuracy: 0.3721 - 156s/epoch - 780ms/step\n",
      "Epoch 93/300\n",
      "200/200 - 157s - loss: 0.9800 - accuracy: 0.3650 - 157s/epoch - 786ms/step\n",
      "Epoch 94/300\n",
      "200/200 - 155s - loss: 0.9784 - accuracy: 0.3725 - 155s/epoch - 773ms/step\n",
      "Epoch 95/300\n",
      "200/200 - 153s - loss: 0.9769 - accuracy: 0.3771 - 153s/epoch - 766ms/step\n",
      "Epoch 96/300\n",
      "200/200 - 157s - loss: 0.9738 - accuracy: 0.3779 - 157s/epoch - 785ms/step\n",
      "Epoch 97/300\n",
      "200/200 - 157s - loss: 0.9721 - accuracy: 0.3825 - 157s/epoch - 784ms/step\n",
      "Epoch 98/300\n",
      "200/200 - 157s - loss: 0.9693 - accuracy: 0.3863 - 157s/epoch - 784ms/step\n",
      "Epoch 99/300\n",
      "200/200 - 156s - loss: 0.9667 - accuracy: 0.3883 - 156s/epoch - 782ms/step\n",
      "Epoch 100/300\n",
      "200/200 - 154s - loss: 0.9629 - accuracy: 0.3869 - 154s/epoch - 771ms/step\n",
      "Epoch 101/300\n",
      "200/200 - 154s - loss: 0.9606 - accuracy: 0.3936 - 154s/epoch - 768ms/step\n",
      "Epoch 102/300\n",
      "200/200 - 13198s - loss: 0.9554 - accuracy: 0.3908 - 13198s/epoch - 66s/step\n",
      "Epoch 103/300\n",
      "200/200 - 130s - loss: 0.9523 - accuracy: 0.3953 - 130s/epoch - 650ms/step\n",
      "Epoch 104/300\n",
      "200/200 - 138s - loss: 0.9465 - accuracy: 0.3958 - 138s/epoch - 690ms/step\n",
      "Epoch 105/300\n",
      "200/200 - 142s - loss: 0.9430 - accuracy: 0.4024 - 142s/epoch - 709ms/step\n",
      "Epoch 106/300\n",
      "200/200 - 144s - loss: 0.9371 - accuracy: 0.4099 - 144s/epoch - 720ms/step\n",
      "Epoch 107/300\n",
      "200/200 - 142s - loss: 0.9307 - accuracy: 0.4112 - 142s/epoch - 709ms/step\n",
      "Epoch 108/300\n",
      "200/200 - 148s - loss: 0.9250 - accuracy: 0.4141 - 148s/epoch - 740ms/step\n",
      "Epoch 109/300\n",
      "200/200 - 149s - loss: 0.9173 - accuracy: 0.4201 - 149s/epoch - 745ms/step\n",
      "Epoch 110/300\n",
      "200/200 - 151s - loss: 0.9111 - accuracy: 0.4209 - 151s/epoch - 755ms/step\n",
      "Epoch 111/300\n",
      "200/200 - 149s - loss: 0.9025 - accuracy: 0.4279 - 149s/epoch - 747ms/step\n",
      "Epoch 112/300\n",
      "200/200 - 149s - loss: 0.8950 - accuracy: 0.4329 - 149s/epoch - 744ms/step\n",
      "Epoch 113/300\n",
      "200/200 - 150s - loss: 0.8858 - accuracy: 0.4389 - 150s/epoch - 748ms/step\n",
      "Epoch 114/300\n",
      "200/200 - 154s - loss: 0.8782 - accuracy: 0.4463 - 154s/epoch - 770ms/step\n",
      "Epoch 115/300\n",
      "200/200 - 154s - loss: 0.8676 - accuracy: 0.4490 - 154s/epoch - 771ms/step\n",
      "Epoch 116/300\n",
      "200/200 - 152s - loss: 0.8594 - accuracy: 0.4560 - 152s/epoch - 762ms/step\n",
      "Epoch 117/300\n",
      "200/200 - 151s - loss: 0.8464 - accuracy: 0.4610 - 151s/epoch - 755ms/step\n",
      "Epoch 118/300\n",
      "200/200 - 155s - loss: 0.8370 - accuracy: 0.4689 - 155s/epoch - 775ms/step\n",
      "Epoch 119/300\n",
      "200/200 - 155s - loss: 0.8267 - accuracy: 0.4721 - 155s/epoch - 773ms/step\n",
      "Epoch 120/300\n",
      "200/200 - 155s - loss: 0.8137 - accuracy: 0.4817 - 155s/epoch - 777ms/step\n",
      "Epoch 121/300\n",
      "200/200 - 155s - loss: 0.8033 - accuracy: 0.4843 - 155s/epoch - 775ms/step\n",
      "Epoch 122/300\n",
      "200/200 - 152s - loss: 0.7902 - accuracy: 0.4961 - 152s/epoch - 762ms/step\n",
      "Epoch 123/300\n",
      "200/200 - 153s - loss: 0.7767 - accuracy: 0.4985 - 153s/epoch - 764ms/step\n",
      "Epoch 124/300\n",
      "200/200 - 157s - loss: 0.7656 - accuracy: 0.5081 - 157s/epoch - 785ms/step\n",
      "Epoch 125/300\n",
      "200/200 - 156s - loss: 0.7522 - accuracy: 0.5169 - 156s/epoch - 778ms/step\n",
      "Epoch 126/300\n",
      "200/200 - 157s - loss: 0.7364 - accuracy: 0.5276 - 157s/epoch - 784ms/step\n",
      "Epoch 127/300\n",
      "200/200 - 156s - loss: 0.7238 - accuracy: 0.5331 - 156s/epoch - 779ms/step\n",
      "Epoch 128/300\n",
      "200/200 - 153s - loss: 0.7121 - accuracy: 0.5411 - 153s/epoch - 763ms/step\n",
      "Epoch 129/300\n",
      "200/200 - 156s - loss: 0.6952 - accuracy: 0.5469 - 156s/epoch - 782ms/step\n",
      "Epoch 130/300\n",
      "200/200 - 157s - loss: 0.6806 - accuracy: 0.5569 - 157s/epoch - 783ms/step\n",
      "Epoch 131/300\n",
      "200/200 - 157s - loss: 0.6672 - accuracy: 0.5624 - 157s/epoch - 783ms/step\n",
      "Epoch 132/300\n",
      "200/200 - 156s - loss: 0.6516 - accuracy: 0.5756 - 156s/epoch - 781ms/step\n",
      "Epoch 133/300\n",
      "200/200 - 154s - loss: 0.6364 - accuracy: 0.5806 - 154s/epoch - 772ms/step\n",
      "Epoch 134/300\n",
      "200/200 - 152s - loss: 0.6239 - accuracy: 0.5863 - 152s/epoch - 761ms/step\n",
      "Epoch 135/300\n",
      "200/200 - 157s - loss: 0.6094 - accuracy: 0.5960 - 157s/epoch - 784ms/step\n",
      "Epoch 136/300\n",
      "200/200 - 157s - loss: 0.5923 - accuracy: 0.6030 - 157s/epoch - 785ms/step\n",
      "Epoch 137/300\n",
      "200/200 - 157s - loss: 0.5772 - accuracy: 0.6119 - 157s/epoch - 786ms/step\n",
      "Epoch 138/300\n",
      "200/200 - 157s - loss: 0.5612 - accuracy: 0.6205 - 157s/epoch - 783ms/step\n",
      "Epoch 139/300\n",
      "200/200 - 153s - loss: 0.5471 - accuracy: 0.6258 - 153s/epoch - 766ms/step\n",
      "Epoch 140/300\n",
      "200/200 - 154s - loss: 0.5291 - accuracy: 0.6348 - 154s/epoch - 769ms/step\n",
      "Epoch 141/300\n",
      "200/200 - 157s - loss: 0.5151 - accuracy: 0.6456 - 157s/epoch - 785ms/step\n",
      "Epoch 142/300\n",
      "200/200 - 160s - loss: 0.4997 - accuracy: 0.6504 - 160s/epoch - 802ms/step\n",
      "Epoch 143/300\n",
      "200/200 - 170s - loss: 0.4849 - accuracy: 0.6590 - 170s/epoch - 852ms/step\n",
      "Epoch 144/300\n",
      "200/200 - 171s - loss: 0.4691 - accuracy: 0.6673 - 171s/epoch - 853ms/step\n",
      "Epoch 145/300\n",
      "200/200 - 153s - loss: 0.4535 - accuracy: 0.6751 - 153s/epoch - 766ms/step\n",
      "Epoch 146/300\n",
      "200/200 - 171s - loss: 0.4384 - accuracy: 0.6820 - 171s/epoch - 856ms/step\n",
      "Epoch 147/300\n",
      "200/200 - 162s - loss: 0.4210 - accuracy: 0.6912 - 162s/epoch - 809ms/step\n",
      "Epoch 148/300\n",
      "200/200 - 156s - loss: 0.4060 - accuracy: 0.6966 - 156s/epoch - 779ms/step\n",
      "Epoch 149/300\n",
      "200/200 - 161s - loss: 0.3899 - accuracy: 0.7093 - 161s/epoch - 805ms/step\n",
      "Epoch 150/300\n",
      "200/200 - 166s - loss: 0.3777 - accuracy: 0.7105 - 166s/epoch - 829ms/step\n",
      "Epoch 151/300\n",
      "200/200 - 159s - loss: 0.3643 - accuracy: 0.7196 - 159s/epoch - 794ms/step\n",
      "Epoch 152/300\n",
      "200/200 - 135s - loss: 0.3483 - accuracy: 0.7302 - 135s/epoch - 675ms/step\n",
      "Epoch 153/300\n",
      "200/200 - 135s - loss: 0.3349 - accuracy: 0.7317 - 135s/epoch - 675ms/step\n",
      "Epoch 154/300\n",
      "200/200 - 137s - loss: 0.3228 - accuracy: 0.7364 - 137s/epoch - 684ms/step\n",
      "Epoch 155/300\n",
      "200/200 - 140s - loss: 0.3072 - accuracy: 0.7460 - 140s/epoch - 702ms/step\n",
      "Epoch 156/300\n",
      "200/200 - 140s - loss: 0.2929 - accuracy: 0.7509 - 140s/epoch - 702ms/step\n",
      "Epoch 157/300\n",
      "200/200 - 142s - loss: 0.2794 - accuracy: 0.7590 - 142s/epoch - 708ms/step\n",
      "Epoch 158/300\n",
      "200/200 - 150s - loss: 0.2677 - accuracy: 0.7678 - 150s/epoch - 748ms/step\n",
      "Epoch 159/300\n",
      "200/200 - 142s - loss: 0.2578 - accuracy: 0.7694 - 142s/epoch - 708ms/step\n",
      "Epoch 160/300\n",
      "200/200 - 144s - loss: 0.2448 - accuracy: 0.7763 - 144s/epoch - 722ms/step\n",
      "Epoch 161/300\n",
      "200/200 - 142s - loss: 0.2358 - accuracy: 0.7811 - 142s/epoch - 712ms/step\n",
      "Epoch 162/300\n",
      "200/200 - 143s - loss: 0.2238 - accuracy: 0.7855 - 143s/epoch - 713ms/step\n",
      "Epoch 163/300\n",
      "200/200 - 143s - loss: 0.2134 - accuracy: 0.7916 - 143s/epoch - 717ms/step\n",
      "Epoch 164/300\n",
      "200/200 - 144s - loss: 0.2057 - accuracy: 0.7967 - 144s/epoch - 718ms/step\n",
      "Epoch 165/300\n",
      "200/200 - 147s - loss: 0.1923 - accuracy: 0.8036 - 147s/epoch - 733ms/step\n",
      "Epoch 166/300\n",
      "200/200 - 148s - loss: 0.1853 - accuracy: 0.8071 - 148s/epoch - 738ms/step\n",
      "Epoch 167/300\n",
      "200/200 - 148s - loss: 0.1782 - accuracy: 0.8082 - 148s/epoch - 742ms/step\n",
      "Epoch 168/300\n",
      "200/200 - 148s - loss: 0.1709 - accuracy: 0.8132 - 148s/epoch - 738ms/step\n",
      "Epoch 169/300\n",
      "200/200 - 149s - loss: 0.1624 - accuracy: 0.8143 - 149s/epoch - 745ms/step\n",
      "Epoch 170/300\n",
      "200/200 - 147s - loss: 0.1550 - accuracy: 0.8207 - 147s/epoch - 736ms/step\n",
      "Epoch 171/300\n",
      "200/200 - 149s - loss: 0.1482 - accuracy: 0.8245 - 149s/epoch - 744ms/step\n",
      "Epoch 172/300\n",
      "200/200 - 147s - loss: 0.1429 - accuracy: 0.8300 - 147s/epoch - 734ms/step\n",
      "Epoch 173/300\n",
      "200/200 - 148s - loss: 0.1371 - accuracy: 0.8320 - 148s/epoch - 738ms/step\n",
      "Epoch 174/300\n",
      "200/200 - 177s - loss: 0.1317 - accuracy: 0.8315 - 177s/epoch - 884ms/step\n",
      "Epoch 175/300\n",
      "200/200 - 182s - loss: 0.1276 - accuracy: 0.8337 - 182s/epoch - 908ms/step\n",
      "Epoch 176/300\n",
      "200/200 - 178s - loss: 0.1223 - accuracy: 0.8397 - 178s/epoch - 892ms/step\n",
      "Epoch 177/300\n",
      "200/200 - 179s - loss: 0.1156 - accuracy: 0.8413 - 179s/epoch - 896ms/step\n",
      "Epoch 178/300\n",
      "200/200 - 179s - loss: 0.1127 - accuracy: 0.8440 - 179s/epoch - 894ms/step\n",
      "Epoch 179/300\n",
      "200/200 - 181s - loss: 0.1103 - accuracy: 0.8442 - 181s/epoch - 905ms/step\n",
      "Epoch 180/300\n",
      "200/200 - 183s - loss: 0.1053 - accuracy: 0.8534 - 183s/epoch - 915ms/step\n",
      "Epoch 181/300\n",
      "200/200 - 181s - loss: 0.1041 - accuracy: 0.8482 - 181s/epoch - 906ms/step\n",
      "Epoch 182/300\n",
      "200/200 - 181s - loss: 0.1010 - accuracy: 0.8524 - 181s/epoch - 906ms/step\n",
      "Epoch 183/300\n",
      "200/200 - 181s - loss: 0.1000 - accuracy: 0.8506 - 181s/epoch - 903ms/step\n",
      "Epoch 184/300\n",
      "200/200 - 181s - loss: 0.0954 - accuracy: 0.8549 - 181s/epoch - 903ms/step\n",
      "Epoch 185/300\n",
      "200/200 - 184s - loss: 0.0935 - accuracy: 0.8558 - 184s/epoch - 921ms/step\n",
      "Epoch 186/300\n",
      "200/200 - 183s - loss: 0.0917 - accuracy: 0.8531 - 183s/epoch - 913ms/step\n",
      "Epoch 187/300\n",
      "200/200 - 178s - loss: 0.0893 - accuracy: 0.8551 - 178s/epoch - 889ms/step\n",
      "Epoch 188/300\n",
      "200/200 - 185s - loss: 0.0865 - accuracy: 0.8599 - 185s/epoch - 923ms/step\n",
      "Epoch 189/300\n",
      "200/200 - 184s - loss: 0.0851 - accuracy: 0.8647 - 184s/epoch - 918ms/step\n",
      "Epoch 190/300\n",
      "200/200 - 184s - loss: 0.0824 - accuracy: 0.8624 - 184s/epoch - 921ms/step\n",
      "Epoch 191/300\n",
      "200/200 - 184s - loss: 0.0816 - accuracy: 0.8623 - 184s/epoch - 920ms/step\n",
      "Epoch 192/300\n",
      "200/200 - 184s - loss: 0.0802 - accuracy: 0.8648 - 184s/epoch - 922ms/step\n",
      "Epoch 193/300\n",
      "200/200 - 184s - loss: 0.0785 - accuracy: 0.8674 - 184s/epoch - 920ms/step\n",
      "Epoch 194/300\n",
      "200/200 - 185s - loss: 0.0786 - accuracy: 0.8663 - 185s/epoch - 927ms/step\n",
      "Epoch 195/300\n",
      "200/200 - 191s - loss: 0.0763 - accuracy: 0.8691 - 191s/epoch - 956ms/step\n",
      "Epoch 196/300\n",
      "200/200 - 187s - loss: 0.0746 - accuracy: 0.8684 - 187s/epoch - 933ms/step\n",
      "Epoch 197/300\n",
      "200/200 - 186s - loss: 0.0740 - accuracy: 0.8675 - 186s/epoch - 928ms/step\n",
      "Epoch 198/300\n",
      "200/200 - 189s - loss: 0.0718 - accuracy: 0.8709 - 189s/epoch - 944ms/step\n",
      "Epoch 199/300\n",
      "200/200 - 181s - loss: 0.0705 - accuracy: 0.8696 - 181s/epoch - 903ms/step\n",
      "Epoch 200/300\n",
      "200/200 - 179s - loss: 0.0698 - accuracy: 0.8688 - 179s/epoch - 893ms/step\n",
      "Epoch 201/300\n",
      "200/200 - 180s - loss: 0.0683 - accuracy: 0.8721 - 180s/epoch - 898ms/step\n",
      "Epoch 202/300\n",
      "200/200 - 194s - loss: 0.0673 - accuracy: 0.8741 - 194s/epoch - 972ms/step\n",
      "Epoch 203/300\n",
      "200/200 - 193s - loss: 0.0660 - accuracy: 0.8763 - 193s/epoch - 963ms/step\n",
      "Epoch 204/300\n",
      "200/200 - 188s - loss: 0.0643 - accuracy: 0.8764 - 188s/epoch - 941ms/step\n",
      "Epoch 205/300\n",
      "200/200 - 177s - loss: 0.0639 - accuracy: 0.8751 - 177s/epoch - 886ms/step\n",
      "Epoch 206/300\n",
      "200/200 - 159s - loss: 0.0625 - accuracy: 0.8741 - 159s/epoch - 794ms/step\n",
      "Epoch 207/300\n",
      "200/200 - 163s - loss: 0.0629 - accuracy: 0.8759 - 163s/epoch - 814ms/step\n",
      "Epoch 208/300\n",
      "200/200 - 161s - loss: 0.0604 - accuracy: 0.8784 - 161s/epoch - 805ms/step\n",
      "Epoch 209/300\n",
      "200/200 - 140s - loss: 0.0610 - accuracy: 0.8773 - 140s/epoch - 700ms/step\n",
      "Epoch 210/300\n",
      "200/200 - 139s - loss: 0.0601 - accuracy: 0.8808 - 139s/epoch - 693ms/step\n",
      "Epoch 211/300\n",
      "200/200 - 141s - loss: 0.0592 - accuracy: 0.8757 - 141s/epoch - 704ms/step\n",
      "Epoch 212/300\n",
      "200/200 - 145s - loss: 0.0582 - accuracy: 0.8786 - 145s/epoch - 725ms/step\n",
      "Epoch 213/300\n",
      "200/200 - 148s - loss: 0.0570 - accuracy: 0.8783 - 148s/epoch - 741ms/step\n",
      "Epoch 214/300\n",
      "200/200 - 140s - loss: 0.0569 - accuracy: 0.8821 - 140s/epoch - 701ms/step\n",
      "Epoch 215/300\n",
      "200/200 - 141s - loss: 0.0564 - accuracy: 0.8844 - 141s/epoch - 704ms/step\n",
      "Epoch 216/300\n",
      "200/200 - 143s - loss: 0.0560 - accuracy: 0.8797 - 143s/epoch - 715ms/step\n",
      "Epoch 217/300\n",
      "200/200 - 146s - loss: 0.0545 - accuracy: 0.8818 - 146s/epoch - 730ms/step\n",
      "Epoch 218/300\n",
      "200/200 - 144s - loss: 0.0549 - accuracy: 0.8845 - 144s/epoch - 718ms/step\n",
      "Epoch 219/300\n",
      "200/200 - 145s - loss: 0.0531 - accuracy: 0.8819 - 145s/epoch - 723ms/step\n",
      "Epoch 220/300\n",
      "200/200 - 145s - loss: 0.0534 - accuracy: 0.8839 - 145s/epoch - 723ms/step\n",
      "Epoch 221/300\n",
      "200/200 - 145s - loss: 0.0521 - accuracy: 0.8862 - 145s/epoch - 727ms/step\n",
      "Epoch 222/300\n",
      "200/200 - 146s - loss: 0.0512 - accuracy: 0.8864 - 146s/epoch - 728ms/step\n",
      "Epoch 223/300\n",
      "200/200 - 147s - loss: 0.0510 - accuracy: 0.8877 - 147s/epoch - 733ms/step\n",
      "Epoch 224/300\n",
      "200/200 - 147s - loss: 0.0504 - accuracy: 0.8861 - 147s/epoch - 735ms/step\n",
      "Epoch 225/300\n",
      "200/200 - 147s - loss: 0.0497 - accuracy: 0.8859 - 147s/epoch - 735ms/step\n",
      "Epoch 226/300\n",
      "200/200 - 148s - loss: 0.0494 - accuracy: 0.8877 - 148s/epoch - 740ms/step\n",
      "Epoch 227/300\n",
      "200/200 - 148s - loss: 0.0491 - accuracy: 0.8853 - 148s/epoch - 739ms/step\n",
      "Epoch 228/300\n",
      "200/200 - 148s - loss: 0.0484 - accuracy: 0.8847 - 148s/epoch - 742ms/step\n",
      "Epoch 229/300\n",
      "200/200 - 149s - loss: 0.0468 - accuracy: 0.8909 - 149s/epoch - 744ms/step\n",
      "Epoch 230/300\n",
      "200/200 - 149s - loss: 0.0469 - accuracy: 0.8888 - 149s/epoch - 747ms/step\n",
      "Epoch 231/300\n",
      "200/200 - 150s - loss: 0.0468 - accuracy: 0.8903 - 150s/epoch - 748ms/step\n",
      "Epoch 232/300\n",
      "200/200 - 149s - loss: 0.0459 - accuracy: 0.8919 - 149s/epoch - 745ms/step\n",
      "Epoch 233/300\n",
      "200/200 - 179s - loss: 0.0453 - accuracy: 0.8912 - 179s/epoch - 895ms/step\n",
      "Epoch 234/300\n",
      "200/200 - 165s - loss: 0.0451 - accuracy: 0.8901 - 165s/epoch - 827ms/step\n",
      "Epoch 235/300\n",
      "200/200 - 166s - loss: 0.0445 - accuracy: 0.8980 - 166s/epoch - 829ms/step\n",
      "Epoch 236/300\n",
      "200/200 - 166s - loss: 0.0438 - accuracy: 0.8958 - 166s/epoch - 832ms/step\n",
      "Epoch 237/300\n",
      "200/200 - 167s - loss: 0.0432 - accuracy: 0.8949 - 167s/epoch - 836ms/step\n",
      "Epoch 238/300\n",
      "200/200 - 167s - loss: 0.0427 - accuracy: 0.8949 - 167s/epoch - 837ms/step\n",
      "Epoch 239/300\n",
      "200/200 - 169s - loss: 0.0426 - accuracy: 0.8943 - 169s/epoch - 843ms/step\n",
      "Epoch 240/300\n",
      "200/200 - 171s - loss: 0.0422 - accuracy: 0.8961 - 171s/epoch - 856ms/step\n",
      "Epoch 241/300\n",
      "200/200 - 169s - loss: 0.0419 - accuracy: 0.8915 - 169s/epoch - 845ms/step\n",
      "Epoch 242/300\n",
      "200/200 - 171s - loss: 0.0413 - accuracy: 0.8935 - 171s/epoch - 855ms/step\n",
      "Epoch 243/300\n",
      "200/200 - 170s - loss: 0.0411 - accuracy: 0.8943 - 170s/epoch - 852ms/step\n",
      "Epoch 244/300\n",
      "200/200 - 172s - loss: 0.0401 - accuracy: 0.8955 - 172s/epoch - 858ms/step\n",
      "Epoch 245/300\n",
      "200/200 - 171s - loss: 0.0401 - accuracy: 0.8979 - 171s/epoch - 853ms/step\n",
      "Epoch 246/300\n",
      "200/200 - 172s - loss: 0.0395 - accuracy: 0.8957 - 172s/epoch - 862ms/step\n",
      "Epoch 247/300\n",
      "200/200 - 172s - loss: 0.0392 - accuracy: 0.8957 - 172s/epoch - 861ms/step\n",
      "Epoch 248/300\n",
      "200/200 - 173s - loss: 0.0390 - accuracy: 0.8978 - 173s/epoch - 864ms/step\n",
      "Epoch 249/300\n",
      "200/200 - 172s - loss: 0.0389 - accuracy: 0.8986 - 172s/epoch - 861ms/step\n",
      "Epoch 250/300\n",
      "200/200 - 173s - loss: 0.0385 - accuracy: 0.9004 - 173s/epoch - 863ms/step\n",
      "Epoch 251/300\n",
      "200/200 - 173s - loss: 0.0383 - accuracy: 0.8945 - 173s/epoch - 864ms/step\n",
      "Epoch 252/300\n",
      "200/200 - 173s - loss: 0.0378 - accuracy: 0.8997 - 173s/epoch - 867ms/step\n",
      "Epoch 253/300\n",
      "200/200 - 173s - loss: 0.0376 - accuracy: 0.8976 - 173s/epoch - 864ms/step\n",
      "Epoch 254/300\n",
      "200/200 - 173s - loss: 0.0370 - accuracy: 0.8982 - 173s/epoch - 865ms/step\n",
      "Epoch 255/300\n",
      "200/200 - 172s - loss: 0.0369 - accuracy: 0.8961 - 172s/epoch - 862ms/step\n",
      "Epoch 256/300\n",
      "200/200 - 174s - loss: 0.0364 - accuracy: 0.8962 - 174s/epoch - 868ms/step\n",
      "Epoch 257/300\n",
      "200/200 - 173s - loss: 0.0358 - accuracy: 0.9030 - 173s/epoch - 863ms/step\n",
      "Epoch 258/300\n",
      "200/200 - 174s - loss: 0.0358 - accuracy: 0.9014 - 174s/epoch - 870ms/step\n",
      "Epoch 259/300\n",
      "200/200 - 173s - loss: 0.0354 - accuracy: 0.9024 - 173s/epoch - 865ms/step\n",
      "Epoch 260/300\n",
      "200/200 - 175s - loss: 0.0352 - accuracy: 0.9025 - 175s/epoch - 873ms/step\n",
      "Epoch 261/300\n",
      "200/200 - 175s - loss: 0.0347 - accuracy: 0.9032 - 175s/epoch - 874ms/step\n",
      "Epoch 262/300\n",
      "200/200 - 174s - loss: 0.0345 - accuracy: 0.9029 - 174s/epoch - 872ms/step\n",
      "Epoch 263/300\n",
      "200/200 - 174s - loss: 0.0346 - accuracy: 0.8994 - 174s/epoch - 868ms/step\n",
      "Epoch 264/300\n",
      "200/200 - 174s - loss: 0.0340 - accuracy: 0.9014 - 174s/epoch - 872ms/step\n",
      "Epoch 265/300\n",
      "200/200 - 174s - loss: 0.0332 - accuracy: 0.9028 - 174s/epoch - 870ms/step\n",
      "Epoch 266/300\n",
      "200/200 - 174s - loss: 0.0333 - accuracy: 0.9031 - 174s/epoch - 872ms/step\n",
      "Epoch 267/300\n",
      "200/200 - 173s - loss: 0.0332 - accuracy: 0.9035 - 173s/epoch - 867ms/step\n",
      "Epoch 268/300\n",
      "200/200 - 175s - loss: 0.0330 - accuracy: 0.9043 - 175s/epoch - 873ms/step\n",
      "Epoch 269/300\n",
      "200/200 - 174s - loss: 0.0328 - accuracy: 0.9014 - 174s/epoch - 871ms/step\n",
      "Epoch 270/300\n",
      "200/200 - 175s - loss: 0.0324 - accuracy: 0.9020 - 175s/epoch - 875ms/step\n",
      "Epoch 271/300\n",
      "200/200 - 173s - loss: 0.0322 - accuracy: 0.9020 - 173s/epoch - 866ms/step\n",
      "Epoch 272/300\n",
      "200/200 - 176s - loss: 0.0315 - accuracy: 0.9069 - 176s/epoch - 879ms/step\n",
      "Epoch 273/300\n",
      "200/200 - 174s - loss: 0.0313 - accuracy: 0.9048 - 174s/epoch - 870ms/step\n",
      "Epoch 274/300\n",
      "200/200 - 175s - loss: 0.0313 - accuracy: 0.9029 - 175s/epoch - 875ms/step\n",
      "Epoch 275/300\n",
      "200/200 - 682s - loss: 0.0309 - accuracy: 0.9056 - 682s/epoch - 3s/step\n",
      "Epoch 276/300\n",
      "200/200 - 153s - loss: 0.0309 - accuracy: 0.9053 - 153s/epoch - 763ms/step\n",
      "Epoch 277/300\n",
      "200/200 - 157s - loss: 0.0306 - accuracy: 0.9027 - 157s/epoch - 787ms/step\n",
      "Epoch 278/300\n",
      "200/200 - 158s - loss: 0.0304 - accuracy: 0.9058 - 158s/epoch - 789ms/step\n",
      "Epoch 279/300\n",
      "200/200 - 162s - loss: 0.0300 - accuracy: 0.9076 - 162s/epoch - 811ms/step\n",
      "Epoch 280/300\n",
      "200/200 - 167s - loss: 0.0300 - accuracy: 0.9060 - 167s/epoch - 834ms/step\n",
      "Epoch 281/300\n",
      "200/200 - 169s - loss: 0.0296 - accuracy: 0.9054 - 169s/epoch - 846ms/step\n",
      "Epoch 282/300\n",
      "200/200 - 172s - loss: 0.0294 - accuracy: 0.9053 - 172s/epoch - 858ms/step\n",
      "Epoch 283/300\n",
      "200/200 - 173s - loss: 0.0295 - accuracy: 0.9058 - 173s/epoch - 865ms/step\n",
      "Epoch 284/300\n",
      "200/200 - 174s - loss: 0.0290 - accuracy: 0.9042 - 174s/epoch - 869ms/step\n",
      "Epoch 285/300\n",
      "200/200 - 175s - loss: 0.0288 - accuracy: 0.9055 - 175s/epoch - 876ms/step\n",
      "Epoch 286/300\n",
      "200/200 - 175s - loss: 0.0286 - accuracy: 0.9082 - 175s/epoch - 874ms/step\n",
      "Epoch 287/300\n",
      "200/200 - 175s - loss: 0.0280 - accuracy: 0.9061 - 175s/epoch - 873ms/step\n",
      "Epoch 288/300\n",
      "200/200 - 176s - loss: 0.0281 - accuracy: 0.9071 - 176s/epoch - 879ms/step\n",
      "Epoch 289/300\n",
      "200/200 - 176s - loss: 0.0277 - accuracy: 0.9070 - 176s/epoch - 882ms/step\n",
      "Epoch 290/300\n",
      "200/200 - 178s - loss: 0.0278 - accuracy: 0.9089 - 178s/epoch - 889ms/step\n",
      "Epoch 291/300\n",
      "200/200 - 175s - loss: 0.0279 - accuracy: 0.9106 - 175s/epoch - 873ms/step\n",
      "Epoch 292/300\n",
      "200/200 - 176s - loss: 0.0276 - accuracy: 0.9101 - 176s/epoch - 878ms/step\n",
      "Epoch 293/300\n",
      "200/200 - 176s - loss: 0.0270 - accuracy: 0.9153 - 176s/epoch - 880ms/step\n",
      "Epoch 294/300\n",
      "200/200 - 178s - loss: 0.0267 - accuracy: 0.9085 - 178s/epoch - 891ms/step\n",
      "Epoch 295/300\n",
      "200/200 - 180s - loss: 0.0267 - accuracy: 0.9094 - 180s/epoch - 898ms/step\n",
      "Epoch 296/300\n",
      "200/200 - 181s - loss: 0.0269 - accuracy: 0.9109 - 181s/epoch - 904ms/step\n",
      "Epoch 297/300\n",
      "200/200 - 182s - loss: 0.0264 - accuracy: 0.9101 - 182s/epoch - 912ms/step\n",
      "Epoch 298/300\n",
      "200/200 - 172s - loss: 0.0258 - accuracy: 0.9090 - 172s/epoch - 858ms/step\n",
      "Epoch 299/300\n",
      "200/200 - 171s - loss: 0.0256 - accuracy: 0.9119 - 171s/epoch - 857ms/step\n",
      "Epoch 300/300\n",
      "200/200 - 171s - loss: 0.0259 - accuracy: 0.9102 - 171s/epoch - 853ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19c0c05be90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X, y=y, batch_size=100, epochs=300, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#load a saved model\n",
    "with open('model', 'rb') as f:\n",
    "   model =  pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 1]\n",
      " [2 7 1]\n",
      " [9 1 2]\n",
      " [0 4 9]\n",
      " [5 2 2]\n",
      " [7 7 3]\n",
      " [3 8 8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwasj\\AppData\\Local\\Temp\\ipykernel_1056\\3106214009.py:14: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np_array = df_input.values.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "# Read the data from the CSV file into a DataFrame, specifying the encoding and column names\n",
    "df_input = pd.read_csv('input.csv', header=None, names=['Draw', 'Date', 'Numbers'], encoding='utf-8')\n",
    "\n",
    "# Replace non-breaking spaces with regular spaces in the Numbers column\n",
    "df_input['Numbers'] = df_input['Numbers'].str.replace('\\xa0', ' ')\n",
    "\n",
    "# Split the Numbers column into separate columns\n",
    "df_input[['Number1', 'Number2', 'Number3']] = df_input['Numbers'].str.split('-', expand=True)\n",
    "\n",
    "# Drop the original Numbers, Date and Draw columns\n",
    "df_input.drop(['Numbers', 'Date', 'Draw'], axis=1, inplace=True)\n",
    "\n",
    "# Convert DataFrame to NumPy array and convert to int data type\n",
    "np_array = df_input.values.astype(np.int)\n",
    "\n",
    "print(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.22844193, -0.87476222, -1.21608757],\n",
       "       [-0.8803407 ,  0.86151851, -1.21608757],\n",
       "       [ 1.55636792, -1.22201836, -0.86682599],\n",
       "       [-1.57654316, -0.18024992,  1.57800507],\n",
       "       [ 0.163963  , -0.87476222, -0.86682599],\n",
       "       [ 0.86016546,  0.86151851, -0.51756441],\n",
       "       [-0.53223947,  1.20877466,  1.22874349]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scaled_to_predict = scaler.transform(np_array)\n",
    "scaled_to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 122ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 7, 3])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(np.array([scaled_to_predict]))\n",
    "\n",
    "scaler.inverse_transform(y_pred).astype(int)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tatua",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
